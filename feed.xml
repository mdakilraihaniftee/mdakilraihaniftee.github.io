<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://mdakilraihaniftee.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://mdakilraihaniftee.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-12T21:50:13+00:00</updated><id>https://mdakilraihaniftee.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Machine Unlearning in MLLMs</title><link href="https://mdakilraihaniftee.github.io/blog/2025/mu-vlm/" rel="alternate" type="text/html" title="Machine Unlearning in MLLMs"/><published>2025-09-20T11:30:00+00:00</published><updated>2025-09-20T11:30:00+00:00</updated><id>https://mdakilraihaniftee.github.io/blog/2025/mu-vlm</id><content type="html" xml:base="https://mdakilraihaniftee.github.io/blog/2025/mu-vlm/"><![CDATA[<p>Machine Unlearning in Vision-Language Models (VLMs) presents unique challenges due to the multi-modal nature of vision and language alignment; below is a brief overview of key considerations.</p> <p><strong>Notes:</strong> <a href="https://docs.google.com/presentation/d/15G9-zH9TCGbMpd3pcSVTM0Cgx-45x-CuLprLWmixqZg/edit?usp=sharing">Link to the pdf</a></p>]]></content><author><name></name></author><category term="blog-review"/><summary type="html"><![CDATA[Machine Unlearning in Vision-Language Models (VLMs) presents unique challenges due to the multi-modal nature of vision and language alignment; below is a brief overview of key considerations.]]></summary></entry><entry><title type="html">Federated Unlearning and it’s Adversarial Threats</title><link href="https://mdakilraihaniftee.github.io/blog/2025/federated-unlearning/" rel="alternate" type="text/html" title="Federated Unlearning and it’s Adversarial Threats"/><published>2025-06-11T11:30:00+00:00</published><updated>2025-06-11T11:30:00+00:00</updated><id>https://mdakilraihaniftee.github.io/blog/2025/federated%20unlearning</id><content type="html" xml:base="https://mdakilraihaniftee.github.io/blog/2025/federated-unlearning/"><![CDATA[<p>Federated Unlearning, like its learning counterpart, is susceptible to various adversarial attacks; here is a brief overview of some prominent ones.</p> <p><strong>Notes:</strong> <a href="https://docs.google.com/presentation/d/1OSEZ_0SjmSP4f_igeZeRTKw23dYDqRQhW5uOus8WeOY/edit?usp=sharing">Link to the pdf</a></p>]]></content><author><name></name></author><category term="blog-review"/><summary type="html"><![CDATA[Federated Unlearning, like its learning counterpart, is susceptible to various adversarial attacks; here is a brief overview of some prominent ones.]]></summary></entry><entry><title type="html">Machine Unlearning and it’s Adversarial Threats</title><link href="https://mdakilraihaniftee.github.io/blog/2025/machine-unlearning/" rel="alternate" type="text/html" title="Machine Unlearning and it’s Adversarial Threats"/><published>2025-04-29T11:30:00+00:00</published><updated>2025-04-29T11:30:00+00:00</updated><id>https://mdakilraihaniftee.github.io/blog/2025/machine%20unlearning</id><content type="html" xml:base="https://mdakilraihaniftee.github.io/blog/2025/machine-unlearning/"><![CDATA[<p>Machine Unlearning methods are increasingly shown to be vulnerable to adversarial attacks; below is a brief overview of some notable attack strategies.</p> <p><strong>Notes:</strong> <a href="https://docs.google.com/presentation/d/1x5wjW8vPYXsBIfAz0-_ZAhFw703dSqde0lOiHWhLmG8/edit?usp=sharing">Link to the pdf</a></p>]]></content><author><name></name></author><category term="blog-review"/><summary type="html"><![CDATA[Machine Unlearning methods are increasingly shown to be vulnerable to adversarial attacks; below is a brief overview of some notable attack strategies.]]></summary></entry><entry><title type="html">Adversarial Attacks and Threats in Federated Learning</title><link href="https://mdakilraihaniftee.github.io/blog/2025/federated_adversarial_attack/" rel="alternate" type="text/html" title="Adversarial Attacks and Threats in Federated Learning"/><published>2025-03-22T11:30:00+00:00</published><updated>2025-03-22T11:30:00+00:00</updated><id>https://mdakilraihaniftee.github.io/blog/2025/federated_adversarial_attack</id><content type="html" xml:base="https://mdakilraihaniftee.github.io/blog/2025/federated_adversarial_attack/"><![CDATA[<p>Federated Learning is vulnerable to a variety of adversarial attacks; here is a brief overview of some of the most common ones. This is one of my personal blog, created during the meeting with collaborators of CCDS.ai where I presented a breif study in attacks in Federated Learning.</p> <p><strong>Notes:</strong> <a href="https://docs.google.com/presentation/d/1Mkqs3ok5Vc2ZLprZvqmBDcwndvvVLWz65S3NzKQ2MK0/edit?usp=sharing">Link to the pdf</a></p>]]></content><author><name></name></author><category term="blog-review"/><summary type="html"><![CDATA[Federated Learning is vulnerable to a variety of adversarial attacks; here is a brief overview of some of the most common ones. This is one of my personal blog, created during the meeting with collaborators of CCDS.ai where I presented a breif study in attacks in Federated Learning.]]></summary></entry><entry><title type="html">Personal Blog: Different Losses of Test Time Adaptation Methods</title><link href="https://mdakilraihaniftee.github.io/blog/2024/losses_of_tta/" rel="alternate" type="text/html" title="Personal Blog: Different Losses of Test Time Adaptation Methods"/><published>2024-01-17T11:30:00+00:00</published><updated>2024-01-17T11:30:00+00:00</updated><id>https://mdakilraihaniftee.github.io/blog/2024/losses_of_tta</id><content type="html" xml:base="https://mdakilraihaniftee.github.io/blog/2024/losses_of_tta/"><![CDATA[<p>There are some important losses which often used or can be used in Test Time Adaptation. This is one of my personal blog, created when I was a Research Assistant in ccds.ai</p> <p><strong>Notes:</strong> <a href="https://drive.google.com/file/d/1XCukUq9sWKPgW2SnwUbmO153GJM3_0WM/view?usp=sharing">Link to the pdf</a></p>]]></content><author><name></name></author><category term="blog-review"/><summary type="html"><![CDATA[There are some important losses which often used or can be used in Test Time Adaptation. This is one of my personal blog, created when I was a Research Assistant in ccds.ai]]></summary></entry><entry><title type="html">Paper Review - Adversarial Attacks in Test Time Adaptation Methods</title><link href="https://mdakilraihaniftee.github.io/blog/2024/presentation_ccds_attacks_in_da/" rel="alternate" type="text/html" title="Paper Review - Adversarial Attacks in Test Time Adaptation Methods"/><published>2024-01-05T11:30:00+00:00</published><updated>2024-01-05T11:30:00+00:00</updated><id>https://mdakilraihaniftee.github.io/blog/2024/presentation_ccds_attacks_in_da</id><content type="html" xml:base="https://mdakilraihaniftee.github.io/blog/2024/presentation_ccds_attacks_in_da/"><![CDATA[<p><strong>Review of the Paper: Uncovering Adversarial Risks of Test-Time Adaptation</strong><br/> <strong>Paper Link:</strong> <a href="[https://arxiv.org/abs/2403.03100](https://arxiv.org/pdf/2301.12576)">arXiv:2301.12576</a></p> <p><strong>Review of the Paper: MedBN: Robust Test-Time Adaptation against Malicious Test Samples</strong><br/> <strong>Paper Link:</strong> <a href="[https://arxiv.org/abs/2403.03100](https://arxiv.org/pdf/2403.19326)">arXiv:2403.19326</a></p> <p><strong>Review of the Paper: R.I.P. : A Simple Black-box Attack on Continual Test-time Adaptation</strong><br/> <strong>Paper Link:</strong> <a href="[https://arxiv.org/abs/2403.03100](https://arxiv.org/pdf/2412.01154)">arXiv:2412.01154</a></p> <p>I had the opportunity to present this paper in our CCDS Lab at IUB, which led to a thought-provoking discussion with lab members and my supervisors on the paper’s methodology and its implications in advancing distribution adjustment research. Below, I am sharing the presentation slides for those interested.</p> <p><strong>Presentation Slides:</strong> <a href="https://docs.google.com/presentation/d/1EMkXMP06sz9YEv_oJLPSdpsVtGXGJvcS_y28MrbiqvI/edit?usp=sharing">Link to slides</a></p>]]></content><author><name></name></author><category term="paper-review"/><summary type="html"><![CDATA[Review of the Paper: Uncovering Adversarial Risks of Test-Time Adaptation Paper Link: arXiv:2301.12576]]></summary></entry></feed>
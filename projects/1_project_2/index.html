<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> User-Guided Image Editing | Md Akil Raihan Iftee </title> <meta name="author" content="Md Akil Raihan Iftee"> <meta name="description" content="Diffusion-Based Image Editing with Vision-Language Instructions"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/prof_pic.jpg?f7d203edd0de5f513cb08f8e1ffe2533"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mdakilraihaniftee.github.io/projects/1_project_2/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Md <span class="font-weight-bold"> Akil </span> Raihan Iftee </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item"> <a class="nav-link" href="/#education"> Education </a> </li> <li class="nav-item"> <a class="nav-link" href="/#workexperience"> Experience </a> </li> <li class="nav-item"> <a class="nav-link" href="/#honowards"> Achievements </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link"><i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">User-Guided Image Editing</h1> <p class="post-description">Diffusion-Based Image Editing with Vision-Language Instructions</p> </header> <article> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <p> <strong>User-Guided Diffusion-Based Image Editing</strong> introduces an intuitive image manipulation pipeline that leverages natural language instructions to edit images with fine spatial precision and semantic alignment. This framework integrates: </p> <ul> <li> <strong>🗣️ LLAVA (Language Processor):</strong> Interprets user instructions and extracts spatial/semantic cues from both image and text.</li> <li> <strong>🧠 SAM (Segmenter):</strong> Identifies and masks target regions guided by LLAVA's attention or grounding hints.</li> <li> <strong>🎨 Stable Diffusion (Editor):</strong> Applies localized image edits guided by the prompt and segmentation mask for coherent and high-quality results.</li> </ul> <p> The system supports a wide range of image edits (e.g., object replacement, color change, background modification) by translating free-form user prompts into targeted modifications — combining precision from segmentation with creativity from diffusion models. </p> <p><strong>📄 Project Paper:</strong> <a href="/assets/pdf/user_guided_editing.pdf" target="_blank">Download PDF</a></p> </div> </div> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/proj11-480.webp 480w,/assets/img/proj11-800.webp 800w,/assets/img/proj11-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/proj11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="User-Guided Editing Framework" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption text-center"> Illustration of our interactive image editing pipeline powered by LLAVA, SAM, and Stable Diffusion. </div> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <p> The pipeline follows a three-stage editing process: </p> <ol> <li> <strong>Instruction Parsing:</strong> LLAVA processes user input and identifies relevant regions and semantics.</li> <li> <strong>Segmentation Guidance:</strong> SAM generates masks for target objects or regions based on visual and textual cues.</li> <li> <strong>Prompt-Guided Editing:</strong> The masked region is edited using a diffusion model that generates coherent outputs matching the instruction.</li> </ol> <p> This architecture empowers non-expert users to achieve high-quality, semantically-aligned edits by combining visual grounding, segmentation, and generative modeling in a unified pipeline. </p> </div> </div> <div class="caption text-center"> Our loss design encourages instruction-grounded generation fidelity while preserving non-edited regions. </div> <h2 id="-references">🔖 References</h2> <ol> <li>H. Liu et al., “LLAVA: Large Language and Vision Assistant,” <em>arXiv:2304.08485</em>, 2023.</li> <li>M. Kirillov et al., “Segment Anything,” <em>arXiv:2304.02643</em>, 2023.</li> <li>R. Rombach et al., “High-Resolution Image Synthesis with Latent Diffusion Models,” <em>CVPR</em>, 2022.</li> <li>K. Zhang et al., “Text-Guided Image Inpainting with Masked Diffusion,” <em>CVPR</em>, 2023.</li> <li>J. Lu et al., “Unified Vision-Language Interface for Image Editing,” <em>arXiv:2310.12345</em>, 2023.</li> </ol> <hr> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Md Akil Raihan Iftee. Last updated: October 03, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-P1606ZLN4B"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P1606ZLN4B");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-teaching",title:"Teaching",description:"Welcome to my teaching portfolio! Here you&#39;ll find an overview of the courses and tutorial sessions I&#39;ve taught, organized by semester and topic. I regularly update this page with slide links and materials for students and collaborators.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-machine-unlearning-in-mllms",title:"Machine Unlearning in MLLMs",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/mu-vlm/"}},{id:"post-federated-unlearning-and-it-39-s-adversarial-threats",title:"Federated Unlearning and it&#39;s Adversarial Threats",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/federated-unlearning/"}},{id:"post-machine-unlearning-and-it-39-s-adversarial-threats",title:"Machine Unlearning and it&#39;s Adversarial Threats",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/machine-unlearning/"}},{id:"post-adversarial-attacks-and-threats-in-federated-learning",title:"Adversarial Attacks and Threats in Federated Learning",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/federated_adversarial_attack/"}},{id:"post-personal-blog-different-losses-of-test-time-adaptation-methods",title:"Personal Blog: Different Losses of Test Time Adaptation Methods",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/losses_of_tta/"}},{id:"post-paper-review-adversarial-attacks-in-test-time-adaptation-methods",title:"Paper Review - Adversarial Attacks in Test Time Adaptation Methods",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/presentation_ccds_attacks_in_da/"}},{id:"news-successfully-defended-undergraduate-thesis-under-the-supervision-of-sk-imran-hossain",title:"Successfully defended undergraduate thesis under the supervision of Sk. Imran Hossain",description:"",section:"News"},{id:"news-started-an-internship-at-the-center-for-computational-amp-amp-data-sciences",title:"Started an internship at the Center for Computational &amp;amp;amp; Data Sciences",description:"",section:"News"},{id:"news-i-have-joined-as-a-research-assistant-at-center-for-computational-amp-amp-data-sciences",title:"I have joined as a Research Assistant at Center for Computational &amp;amp;amp; Data...",description:"",section:"News"},{id:"news-i-am-excited-to-share-that-3-of-my-papers-have-been-accepted-for-presentation-at-the-27th-international-conference-on-computer-and-information-technology-iccit-2024",title:"I am excited to share that 3 of my papers have been accepted...",description:"",section:"News"},{id:"news-our-fedctta-paper-got-accepted-in-ijcnn-2025",title:"Our FedCTTA paper got accepted in  IJCNN 2025",description:"",section:"News"},{id:"news-two-of-our-papers-bd-open-lulc-map-and-rgc-bent-have-been-accepted-in-ieee-international-conference-on-image-processing-icip-2025",title:"Two of our papers BD Open LULC Map and RGC-BENT have been accepted...",description:"",section:"News"},{id:"news-reaching-200-citations-of-my-research-papers-check-in-my-google-scholar",title:"Reaching 200+ Citations of my research papers. Check in my Google Scholar.",description:"",section:"News"},{id:"news-our-slomo-fast-and-pfedbbn-are-avialable-in-online-please-have-a-look-at-the-papers",title:"Our SloMo-Fast and pFedBBN are avialable in online. Please have a look at...",description:"",section:"News"},{id:"projects-human-activity-recognition-through-wearable-sensor-video",title:"Human Activity Recognition through Wearable Sensor, Video",description:"Multimodal Alignment from Video, Sensor(accelerometer, gyroscope, and orientation), Language",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-fedbalancetta",title:"FedBalanceTTA",description:"Class Imbalance Mitigation Federated Test-Time Adaptation",section:"Projects",handler:()=>{window.location.href="/projects/1_project_1/"}},{id:"projects-user-guided-image-editing",title:"User-Guided Image Editing",description:"Diffusion-Based Image Editing with Vision-Language Instructions",section:"Projects",handler:()=>{window.location.href="/projects/1_project_2/"}},{id:"projects-semantic-cognitive-distraction-attack-scd-in-llm",title:"Semantic Cognitive Distraction Attack (SCD) in LLM",description:"Multimodal Jailbreak Attack via Contextual Reasoning Manipulation",section:"Projects",handler:()=>{window.location.href="/projects/1_project_3/"}},{id:"projects-corona-app",title:"Corona App",description:"Real-time COVID-19 Tracker App Using Flutter &amp; REST API",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-ludo-2-0",title:"Ludo 2.0",description:"Python-Based Human vs AI Board Game",section:"Projects",handler:()=>{window.location.href="/projects/2_project_1/"}},{id:"projects-online-market",title:"Online Market",description:"ASP.NET Core MVC-based E-commerce Platform",section:"Projects",handler:()=>{window.location.href="/projects/2_project_2/"}},{id:"projects-video-streaming-dbms",title:"Video Streaming DBMS",description:"Oracle SQL-based Database System for a YouTube-like Platform",section:"Projects",handler:()=>{window.location.href="/projects/2_project_3/"}},{id:"projects-federated-personalized-scanpath",title:"Federated Personalized Scanpath",description:"Federated Learning",section:"Projects",handler:()=>{window.location.href="/projects/2_project_5/"}},{id:"projects-controllable-3d-user-interface-generation",title:"Controllable 3D User Interface Generation",description:"Multimodal Learning, 3D, Generative AI",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-federated-personalized-eye-scanpath",title:"Federated Personalized Eye Scanpath",description:"Federated Learning + Trustworthy ML",section:"Projects",handler:()=>{window.location.href="/projects/3_project_1/"}},{id:"projects-gaze-enhanced-multimodal-interaction",title:"Gaze-Enhanced Multimodal Interaction",description:"Multimodal Learning",section:"Projects",handler:()=>{window.location.href="/projects/3_project_2/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%69%66%74%65%65%31%38%30%37%30%30%32@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/mdakilraihaniftee","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/mdakilraihaniftee","_blank")}},{id:"social-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Akil Raihan Iftee/","_blank")}},{id:"social-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=x1ueJ5UAAAAJ&hl","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>